# ğŸŒ± Carbon Footprint Predictor

A machine learning model to predict individual weekly carbon footprint based on behavioral and lifestyle features such as Diet, Transport, Electricity Usage, Vehicle Type, etc.

### AI/ML Entry-Level Assessment Project by Basit Bashir Wani

---

## ğŸ“‚ Dataset Used

* **Name:** Carbon Footprint.csv
* **Source:** Retrieved from a web-based source.

* **Features:**

  * Diet (Categorical)
  * Transport(Categorical)
  * Electricity Usage (kWh)
  * Vehicle Type(Categorical)
  * Vehicle Monthly Distance(Km)
  * Heating Energy Source(Categorical)
  * ...and more
* **Target:** Weekly Carbon Footprint (in kg COâ‚‚ equivalent)

---
Approach(Summary)
 * âœ… Cleaned and preprocessed the dataset, handling missing values and encoding categorical variables.
 * âš™ï¸ Built a reusable pipeline for scaling, encoding, and imputation.
 * ğŸŒ² Trained a Decision Tree Regressor for prediction.
 * ğŸ› ï¸ Tuned model using RandomizedSearchCV to optimize performance.
 * ğŸ“Š Evaluated using RÂ² and RMSE metrics, both before and after tuning.
 * ğŸ“‰ Analyzed residuals and model outputs for bias and variance.


---
## ğŸ§  Detailed Approach

### 1. Data Cleaning & Preprocessing
* Checked for missing values and handled them appropriately.

* Developed a reusable preprocessing pipeline that:
  * Handled missing values using a median imputation strategy with SimpleImputer(strategy="median")

  * Encodes categorical variables (like Transport Mode) with OneHotEncoder

  * Scales numerical features using StandardScaler(for linear regressor)

* This pipeline ensures streamlined and consistent data handling for training and inference.
### 2. Model Building

* Implemented a **Decision Tree Regressor** to predict carbon footprint.
* Performed hyperparameter tuning using RandomizedSearchCV with the following parameter distributions:
  * criterion: ['squared_error', 'friedman_mse']
  * splitter: ['best', 'random']
  * max_depth: integers from 3 to 20
  * max_features: ['sqrt', 'log2', None]

* This comprehensive tuning helped optimize model performance and prevent overfitting.


### 3. Evaluation

* Used metrics:
   * Before Hyperparameter Tunning: 
     * RÂ² Score: 0.6720282827473432
     * Mean Squared Error (MSE): 472588.8262195122
     * Root Mean Squared Error (RMSE): 687
   * After Hyperparameter Tunning: 
     * RÂ² Score: 0.7404797613009263
     * Mean Squared Error (MSE): 373954.0897440275
     * Root Mean Squared Error (RMSE): 611
* These results indicate a strong predictive ability with acceptable error margins.

---
## ğŸ“ˆ Results Summary

- Final RÂ² Score: **0.74(The model predicts COâ‚‚ fairly well â€” it's right about 74% of the time)**
- RMSE: **611 kg COâ‚‚(On average, the model's predictions are off by 611 kilograms of COâ‚‚.)**
- Model effectively captures nonlinear relationships using a Decision Tree.
- Residual analysis confirms minimal bias or variance issues.


## ğŸ“Š Bonus Highlights

* ğŸ“Œ Predicted vs Actual Plot: A scatter plot (like the one shown above) that compares true target values against model predictions. The red dashed line indicates ideal predictions â€” closer clustering around this line suggests better model performance.

* ğŸ“‰ Residual Plot: The residual plot reveals a fairly random scatter around zero, suggesting that the model captures the main patterns well. However, the spread at higher predicted values hints at potential variance issues or room for improvement in those ranges.
  
* ğŸ“ŠğŸ” Feature Importance Plot: Our model reveals that how far you drive and how often you fly are the biggest contributors to your environmental footprint. Surprisingly, lifestyle choices like diet and electricity usage played a much smaller role in the predictions â€” highlighting the outsized impact of transportation habits.

* ğŸ§© Modular Code Snippets: Clean, reusable code blocks for data preprocessing, model training, evaluation, and visualization to support easy experimentation and future updates.

---

## âš™ï¸ Dependencies

* To run this project, ensure the following Python libraries are installed:
  * NumPy â€“ for numerical computations
  * Pandas â€“ for data manipulation and analysis
  * Matplotlib â€“ for plotting visualizations (e.g., Predicted vs Actual, Residual Plot)
  * Scikit-learn â€“ for model building and evaluation (e.g., Decision Tree Regressor)

```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

Or use the provided `requirements.txt` and run: 
```bash
pip install -r requirements.txt
```
## ğŸ‘¨â€ğŸ’» About the Author

**Basit Bashir Wani**  
*B.Tech Electronics and Communication Engineering (ECE)*  
*National Institute of Technology, Srinagar*
